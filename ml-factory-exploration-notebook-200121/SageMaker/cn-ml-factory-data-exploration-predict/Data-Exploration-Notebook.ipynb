{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "from base64 import b64decode\n",
    "import json\n",
    "source_config = json.loads(b64decode(\"<source_config>\".encode(\"ascii\")).decode(\"ascii\"))\n",
    "metadata = json.loads(b64decode(\"<metadata>\".encode(\"ascii\")).decode(\"ascii\"))\n",
    "print(\"Source Config: {}\".format(source_config))\n",
    "print(\"Input Tables MetaData: {}\".format(metadata))\n",
    "try:\n",
    "    import pandas_profiling\n",
    "except:\n",
    "    !sudo /home/ec2-user/anaconda3/bin/conda update -n amazonei_tensorflow_p36 --all -y\n",
    "    !sudo /home/ec2-user/anaconda3/bin/conda install -c conda-forge -n amazonei_tensorflow_p36 pandas-profiling imagehash -y\n",
    "    !sudo /home/ec2-user/anaconda3/bin/conda update -n amazonei_tensorflow_p36 ipywidgets -y\n",
    "finally:\n",
    "    import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_location = source_config['input_s3_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Column Description'''\n",
    "def column_description(df):\n",
    "    start_time = time.time()\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
    "    summary = summary.reset_index()\n",
    "    summary['Name'] = summary['index']\n",
    "    summary = summary[['Name','dtypes']]\n",
    "    summary['Missing'] = (df.isnull() | df.isna()).sum().values\n",
    "    summary['Uniques'] = df.nunique().values\n",
    "    summary['Mean'] = df.mean().values\n",
    "    summary['STD'] = df.std().values\n",
    "    summary['Min'] = df.min().values\n",
    "    summary['Max'] = df.max().values\n",
    "    summary['First Value'] = df.iloc[0].values\n",
    "    summary['Second Value'] = df.iloc[1].values\n",
    "    summary['Third Value'] = df.iloc[2].values\n",
    "    print(f'Completed in {time.time()-start_time} seconds..')\n",
    "    return summary.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes Dataframe and Threshold as input\n",
    "Returns two set of columns based on cardinality \n",
    "\"\"\"\n",
    "def seperate_categorical_cols(df, threshold):\n",
    "    categorical_cols = df.select_dtypes(include='object')\n",
    "    one_hot_cols = []\n",
    "    other_cols = []\n",
    "    for col in categorical_cols:\n",
    "        print(col, df[col].nunique())\n",
    "        if df[col].nunique() <= threshold:\n",
    "            one_hot_cols.append(col)\n",
    "        else :\n",
    "            other_cols.append(col)\n",
    "    return one_hot_cols, other_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot columns wrt Target columns\n",
    "\"\"\"\n",
    "def plot_columns(df, plot_cols, target_col='success'):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    num_cols = len(plot_cols)\n",
    "    if num_cols > 3:\n",
    "        print('Max 3 columns supported till now!!')\n",
    "        return\n",
    "    \n",
    "    if num_cols == 1:\n",
    "        col_name = plot_cols[0]\n",
    "        df_array = [df[df[target_col]==success_val][col_name] for success_val in df[target_col].unique()]\n",
    "        plt.hist(df_array, stacked=True, label=df[target_col].unique())\n",
    "        plt.legend()\n",
    "    if num_cols == 2:\n",
    "        df.plot.scatter(x=plot_cols[0], y=plot_cols[1], c=target_col, colormap='viridis')\n",
    "    if num_cols == 3:\n",
    "        fig = px.scatter_3d(\n",
    "            df,\n",
    "            x=plot_cols[0],\n",
    "            y=plot_cols[1],\n",
    "            z=plot_cols[2],\n",
    "            color=target_col\n",
    "        )\n",
    "        fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "li = []\n",
    "for file in fs.ls(input_data_location):\n",
    "    try:\n",
    "        li.append(pd.read_csv(\"s3://{}\".format(file)))\n",
    "    except:\n",
    "#         print('file {} is not readable'.format(file))\n",
    "        pass\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "column_description(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_columns(df, ['sepal_length'], 'species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_columns(df, ['sepal_length', 'sepal_width'], 'species_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_columns(df, ['sepal_length', 'sepal_width', 'petal_width'], 'species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exploration_profile = pandas_profiling.ProfileReport(df)\n",
    "data_exploration_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to save the above data explorations report to your s3 bucket as html file,\n",
    "#uncomment the code below and populate the required placeholders\n",
    "\n",
    "# file_name = \"\"             #string placeholder\n",
    "# s3_bucket_path = \"\"           #string placeholder\n",
    "\n",
    "# file_name = \"{}.html\".format(file_name)\n",
    "# data_exploration_profile.to_file(output_file=file_name)\n",
    "# s3_client = boto3.client('s3')\n",
    "# response = s3_client.upload_file(file_name, s3_bucket_path, file_name\")\n",
    "# print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
